{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "babeb32eb84b490789446879afe01bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b63ecba40484685a313b32615ad8d0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72bfee0d5e614f7e91a16ab958dbfba0",
              "IPY_MODEL_932f591978c54acf9dc872676e6c2d6a"
            ]
          }
        },
        "5b63ecba40484685a313b32615ad8d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72bfee0d5e614f7e91a16ab958dbfba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c27dd275738e4148addffc71fc363fc7",
            "_dom_classes": [],
            "description": "  4%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 10000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 406,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45425e06fee142b09ec2970c9e615cb6"
          }
        },
        "932f591978c54acf9dc872676e6c2d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c72db146cd54d798d29ca78bb4e5c96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 405/10000 [05:54&lt;2:19:58,  1.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a9f8aaf851a43f49639ce23013f32fd"
          }
        },
        "c27dd275738e4148addffc71fc363fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45425e06fee142b09ec2970c9e615cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c72db146cd54d798d29ca78bb4e5c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a9f8aaf851a43f49639ce23013f32fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhpU_1d7E9KZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d749de6-100b-4f7a-d9b7-0b32e2e9d5fb"
      },
      "source": [
        "from __future__ import division\n",
        "import argparse\n",
        "import pandas as pd\n",
        "\n",
        "# useful stuff\n",
        "import numpy as np\n",
        "from scipy.special import expit\n",
        "from sklearn.preprocessing import normalize\n",
        "from random import choices\n",
        "from tqdm.notebook import tqdm\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import re\n",
        "import pickle\n",
        "import time\n",
        "import copy"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7qvo5FZE_uy",
        "outputId": "f4d3716f-a839-4e3d-817c-0883b89039c4"
      },
      "source": [
        "## MOUNT DRIVE \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKucJqy1Gt9i"
      },
      "source": [
        "def preprocess(sentence) :\n",
        "  sentence = re.sub(\"[^a-zA-Z0-9]\",\" \", sentence) ## remove non alpha numerical  caracters\n",
        "  sentence = re.sub(\"[0-9]+\",\"NUMTOKEN\", sentence) ## create NUMTOKEN word for numbers\n",
        "  return sentence\n",
        "  \n",
        "def text2sentences(path):\n",
        "\t# feel free to make a better tokenization/pre-processing\n",
        "\tsentences = []\n",
        "\twith open(path) as f:\n",
        "\t\tfor l in f:\n",
        "\t\t\tsentences.append( word_tokenize(preprocess(l.lower())))\n",
        "\treturn sentences\n",
        "\n",
        "def loadPairs(path):\n",
        "\tdata = pd.read_csv(path, delimiter='\\t')\n",
        "\tpairs = zip(data['word1'],data['word2'],data['similarity'])\n",
        "\treturn pairs"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLssLDyQDxE3"
      },
      "source": [
        "class SkipGram():\n",
        "    def __init__(self, sentences, lr = 1e-2 , nEmbed=100, negativeRate=5, winSize = 5, minCount = 2):\n",
        "      self.w2id = {} # word to ID mapping\n",
        "      \n",
        "      self.vocab = [] # list of valid words\n",
        "      self.occurences = defaultdict(int)\n",
        "      self.minCount = minCount\n",
        "      self.get_vocab(sentences)\n",
        "      self.trainset = self.subsample(sentences)\n",
        "      ## Initialize weights \n",
        "      self.W_  = np.random.normal(0, 1, (nEmbed,len(self.vocab)))\n",
        "      self.C_ = np.random.normal(0, 1, (nEmbed,len(self.vocab)))\n",
        "      ## learning rate\n",
        "      self.lr_ = lr\n",
        "      self.neg_ = negativeRate\n",
        "      self.winSize = winSize\n",
        "      self.loss= []\n",
        "      ## random vector for unknown words in test time.\n",
        "      self.random_vector = np.random.normal(0,1,(nEmbed,1))\n",
        "    def get_vocab(self,sentences) :\n",
        "        \"\"\"\n",
        "        Create vocab , word to id dict and a dict of occurences\n",
        "        \"\"\" \n",
        "        for sentence in sentences : \n",
        "          for word in sentence :\n",
        "            self.occurences[word]+=1\n",
        "\n",
        "        self.occurences  = dict(self.occurences)\n",
        "        ## filter by mincount\n",
        "        self.occurences  = {k: v for k, v in self.occurences.items() if v>= self.minCount}\n",
        "        self.vocab = list(self.occurences.keys())\n",
        "        self.w2id = dict(zip(self.vocab,range(len(self.vocab))))\n",
        "\n",
        "        total_occurences = sum(list(self.occurences.values())) ## normalize\n",
        "        self.occurences = {k:v/total_occurences for k,v in self.occurences.items()} ## normalize \n",
        "    def subsample(self,sentences) :\n",
        "      \"\"\"\n",
        "      This function subsamples words that are frequent in the dataset.\n",
        "      \"\"\"\n",
        "      trainset_ = []\n",
        "      for sentence in sentences :\n",
        "        current = []\n",
        "        for word in sentence :\n",
        "          ## if not in vocab (filtered by min count)\n",
        "          if word not in self.vocab : \n",
        "            continue\n",
        "          ## This is the probability to keep the word. The formulation is taken from word2vec paper. \n",
        "          prob = (np.sqrt(self.occurences[word]/1e-3)+1) * (1e-3/self.occurences[word])\n",
        "          k = random.random()\n",
        "          if k<prob :\n",
        "            current.append(word) \n",
        "        trainset_.append(current)\n",
        "      return trainset_\n",
        "\n",
        "\n",
        "    def sample(self, omit):\n",
        "        \"\"\"samples negative words, ommitting those in set omit\"\"\"\n",
        "        l = list(self.w2id.values())\n",
        "        for x in omit :\n",
        "          l.remove(x) ## faster than list comprehension\n",
        "        return choices(l, k = self.neg_)\n",
        "        \n",
        "    def onehot(self,Id_) :\n",
        "        \"\"\"\n",
        "        One hot code labeling of the word indexes.\n",
        "        \"\"\"\n",
        "        ## in case we want to encode one index\n",
        "        if isinstance(Id_, int):\n",
        "          m = np.zeros((len(self.vocab),1))\n",
        "          m[Id_-1] = 1\n",
        "          return m\n",
        "        else : ## multiple indexes\n",
        "          m = np.zeros((len(self.vocab),len(Id_)))\n",
        "          for k,index in enumerate(Id_) :\n",
        "            m[index-1,k] = 1\n",
        "          return m \n",
        "    def sigmoid(self,x) :\n",
        "        return (1/(1+np.exp(-x)))\n",
        "    def train(self):\n",
        "        self.trainWords , self.acc = 0 , 0 \n",
        "        for counter, sentence in tqdm(enumerate(self.trainset) , total = len(self.trainset)):\n",
        "            sentence = list(filter(lambda word: word in self.vocab, sentence))\n",
        "\n",
        "            for wpos, word in enumerate(sentence):\n",
        "                wIdx = self.w2id[word]\n",
        "                winsize = np.random.randint(self.winSize) + 1\n",
        "                start = max(0, wpos - winsize)\n",
        "                end = min(wpos + winsize + 1, len(sentence))\n",
        "\n",
        "                for context_word in sentence[start:end]:\n",
        "                    ctxtId = self.w2id[context_word]\n",
        "                    if ctxtId == wIdx: continue\n",
        "                    negativeIds = self.sample({wIdx, ctxtId})\n",
        "                    self.trainWord(wIdx, ctxtId, negativeIds)\n",
        "                    self.trainWords += 1\n",
        "                  \n",
        "            if counter % 100 == 0:\n",
        "                print (' > training %d of %d' % (counter, len(self.trainset)))\n",
        "                acc_norm = self.acc/((1+self.neg_) * self.trainWords)\n",
        "                print('loss : ',acc_norm)\n",
        "                self.loss.append(acc_norm)\n",
        "                self.trainWords = 0\n",
        "                self.acc = 0.\n",
        "\n",
        "    def trainWord(self, wordId, contextId, negativeIds):\n",
        "        t1 = time.time()\n",
        "    \n",
        "        y_context = self.onehot(contextId)\n",
        "        z_negatives = self.onehot(negativeIds)\n",
        "        x_w = self.W_[:,wordId-1].reshape(-1,1)\n",
        "        y_c = self.C_[:,contextId-1].reshape(-1,1)\n",
        "        Z_c = self.C_[:,[neg_id -1 for neg_id in negativeIds]]\n",
        "        t2 = time.time()\n",
        "        ## compute gradients \n",
        "        negative_grad_W = np.zeros((self.W_.shape[0],1))\n",
        "        negative_grad_C= np.zeros((1,self.C_.shape[1]))\n",
        "        \n",
        "        \n",
        "        sig_neg = self.sigmoid(x_w.T @ Z_c) \n",
        "        negative_grad_W =  - np.sum(sig_neg * Z_c, axis = 1).reshape(-1,1)\n",
        "        negative_grad_C =  - np.sum(sig_neg * z_negatives ,axis=1).reshape(1,-1)\n",
        "        self.acc -= np.sum(np.log(1-sig_neg + 1e-6),axis=1)[0]\n",
        "        t3 = time.time()\n",
        "        \n",
        "        sig_pos = self.sigmoid( - x_w.T @ y_c)[0][0]\n",
        "        self.acc -= np.log(1-sig_pos + 1e-6) \n",
        "        grad_w = np.zeros_like(self.W_)\n",
        "        grad_w [:,wordId-1] = (sig_pos * y_c   + negative_grad_W).squeeze()\n",
        "        grad_c = x_w @ (sig_pos * y_context.T  + negative_grad_C )\n",
        "        t4 = time.time()\n",
        "        ## update weights \n",
        "        self.W_+=self.lr_ * grad_w ## gradient ascent since we want the argmax\n",
        "        self.C_+=self.lr_ * grad_c\n",
        "        \"\"\"\n",
        "        print('x_w',t2 - t1)\n",
        "        print(\"negative grad\",t3-t2)\n",
        "        print(\"grad\" , t4 - t3)\n",
        "        \"\"\"\n",
        "    def save(self,path):\n",
        "        with open(path, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    def similarity(self,word1,word2):\n",
        "        \"\"\"\n",
        "        computes similiarity between the two words. unknown words are mapped to one common vector\n",
        "        :param word1:\n",
        "        :param word2:\n",
        "        :return: a float \\in [0,1] indicating the similarity (the higher the more similar)\n",
        "        \"\"\"\n",
        "        if word1 not in self.vocab  : \n",
        "          x_w = self.random_vector\n",
        "        else : \n",
        "          id1 = self.w2id[word1]\n",
        "          x_w = self.W_ @ self.onehot(id1)\n",
        "\n",
        "        if word2 not in self.vocab  : \n",
        "          x_c = self.random_vector\n",
        "        else : \n",
        "          id2 = self.w2id[word2]\n",
        "          x_c = self.C_ @ self.onehot(id2)\n",
        "\n",
        "        return self.sigmoid(x_w.T @ x_c)[0][0]\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def load(path):\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmvVKV1fFxqO"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW93378zFzOn"
      },
      "source": [
        "test = False\n",
        "text_path = '/content/drive/MyDrive/data_CS_MVA/NLP/train_10000.txt'"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HteUs8nhFyjk"
      },
      "source": [
        "sentences = text2sentences(text_path)\n",
        "sg = SkipGram(sentences , lr= 1e-2 , nEmbed = 100, negativeRate= 5)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "babeb32eb84b490789446879afe01bb3",
            "5b63ecba40484685a313b32615ad8d0b",
            "72bfee0d5e614f7e91a16ab958dbfba0",
            "932f591978c54acf9dc872676e6c2d6a",
            "c27dd275738e4148addffc71fc363fc7",
            "45425e06fee142b09ec2970c9e615cb6",
            "5c72db146cd54d798d29ca78bb4e5c96",
            "3a9f8aaf851a43f49639ce23013f32fd"
          ]
        },
        "id": "hjxtGz1KTCrK",
        "outputId": "76343dab-dbe6-48ff-afdd-b4d218676d6b"
      },
      "source": [
        "sg.train()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "babeb32eb84b490789446879afe01bb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " > training 0 of 10000\n",
            "loss :  3.828682536313354\n",
            " > training 100 of 10000\n",
            "loss :  3.556772192589172\n",
            " > training 200 of 10000\n",
            "loss :  3.5111367214236635\n",
            " > training 300 of 10000\n",
            "loss :  3.3726024771804326\n",
            " > training 400 of 10000\n",
            "loss :  3.2781092341620157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EATuhvjfS3O7"
      },
      "source": [
        "sg.save('/content/drive/MyDrive/model_skip.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}